- name: deployment_name
  value: petals-worker-1
  default: petals-worker-1
  description: "Name of the deployment job"

- name: priority
  value: high-priority
  default: high-priority
  description: "Priority for this job"

- name: storage
  value: "pool-cache"
  default: "pool-cache"
  description: "Pool storage to use to cache partial weights for serving the model (chat app)"

- name: mount_path
  value: ""
  default: ""
  description: "Local storage for model weights (workers). Empty for root ('/') "

- name: max_workers
  value: "1"
  default: "1"
  description: "Maximum number of workers to spawn in the cluster"

- name: hf_token
  value: <your token here>
  default: null
  description: "Huggingface token, required to load model weights"

- name: min_cpus
  value: "2"
  default: "2"
  description: "CPUs per single worker (final one = cpus * num_workers)"

- name: min_memory
  value: "4"
  default: "4"
  description: "RAM memory per single worker (final one = memory * num_workers)"

- name: max_cpus
  value: "12"
  default: "12"
  description: "CPUs per single worker (final one = cpus * num_workers)"

- name: max_memory
  value: "16"
  default: "16"
  description: "RAM memory per single worker (final one = memory * num_workers)"

- name: ephemeral_storage
  value: "30"
  default: "30"
  description: "Storage reserved per worker to download model shards weights"

- name: gpus
  value: "1"
  default: "1"
  description: "GPUs per single worker (final one = gpus * num_workers)"

- name: model_id
  value: "mistralai/Mixtral-8x22B-Instruct-v0.1"
  default: "mistralai/Mixtral-8x22B-Instruct-v0.1"
  description: ""

- name: initial_peers
  value: ""
  default: ""
  description: ""

- name: extra
  value: ""
  default: ""
  description: "Extra parameters for Petals cli"

# must contain the list of ports to enable in the leader node
- name: endpoint_ports
  value: "5000,5001"
  default: "5000,5001"
  description: "[DO NOT CHANGE] Ports opened on master node (will be shown as endpoints for the job)"