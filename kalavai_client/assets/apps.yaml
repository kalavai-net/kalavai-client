helmDefaults:
  timeout: 1200

repositories:
  # amd gpu operator: https://github.com/ROCm/gpu-operator
  - name: rocm
    url: https://rocm.github.io/gpu-operator
  # required by rocm
  # - name: jetstacks
  #   url: https://charts.jetstack.io
  ###
  - name: kuberay
    url: https://ray-project.github.io/kuberay-helm/
  - name: nvidia
    url: https://helm.ngc.nvidia.com/nvidia
  - name: kalavai
    url: https://kalavai-net.github.io/helm-charts/
  - name: longhorn
    url: https://charts.longhorn.io
  - name: volcano-sh
    url: https://volcano-sh.github.io/helm-charts
  - name: prometheus-community # prometheus
    url: https://prometheus-community.github.io/helm-charts
  - name: opencost-charts
    url: https://opencost.github.io/opencost-helm-chart
  - name: minio
    url: https://charts.min.io/
  - name: langfuse
    url: https://langfuse.github.io/langfuse-k8s
  - name: hami-charts
    url: https://project-hami.github.io/HAMi
  - name: lago
    url: https://charts.getlago.com

releases:
  # HACK: to avoid racing conditions with traefik not being ready, the CRDs are installed
  # in the base kalavai-runner image, then here we apply artificial wait to give them time
  - name: cert-manager
    namespace: cert-manager
    chart: oci://quay.io/jetstack/charts/cert-manager
    version: "v1.19.1"
    installed: {{deploy_cert_manager|default("False", true)}}
    set:
      - name: crds.enabled
        value: false  # We'll handle CRDs manually in the kalavai-runner
    hooks:
      # --- Step 1: Wait to ensure CRDs and traefik are ready (presync)
      - events: ["presync"]
        showlogs: true
        command: "bash"
        args:
          - "-c"
          - |
            echo ">>> Waiting for CRDs to establish and traefik to be ready....$(date)"
            sleep 240
            echo ">>> PRESYNC completed: $(date)"
  # - name: cert-manager
  #   namespace: cert-manager
  #   chart: oci://quay.io/jetstack/charts/cert-manager
  #   version: "v1.19.1"
  #   installed: {{deploy_cert_manager|default("False", true)}}
  #   set:
  #   - name: crds.enabled
  #     value: true
  - name: rocm
    needs: 
    - cert-manager/cert-manager
    namespace: kalavai
    chart: rocm/gpu-operator-charts
    installed: {{deploy_rocm|default("false", true)}}
    version: "1.4.0"
  # - name: lago
  #   namespace: kalavai
  #   chart: lago/lago
  #   installed: {{deploy_lago|default("false", true)}}
  #   version: 1.27.1
  #   set:
  #   # internal postgresql
  #   - name: postgresql.enabled
  #     value: false
  #   # external sql
  #   - name: global.databaseUrl #postgres URL postgresql://USER:PASSWORD@HOST:PORT/DB
  #     value: ""
  #   # internal redis
  #   - name: redis.enabled
  #     value: false
  #   # external
  #   - name: global.redisUrl #redis URL redis://â€¦
  #     value: ""
  #   # s3
  #   - name: global.s3.enabled
  #     value: false
  #   # minio internal
  #   - name: minio.enabled
  #     value: true
  #   # config
  #   - name: apiUrl
  #     value: http://{{cluster_ip}}:32000
  #   - name: frontUrl
  #     value: http://{{cluster_ip}}:30080
    # how do we expose?
    # - name: external.api.nodePort
    #   value: 32000
    # - name: external.front.nodePort
    #   value: 30080
  - name: lago
    namespace: kalavai
    chart: kalavai/lago
    installed: {{deploy_lago|default("false", true)}}
    set:
    - name: external.api.nodePort
      value: 32000
    - name: external.front.nodePort
      value: 30080
    - name: apiUrl
      value: http://{{cluster_ip}}:32000
    - name: frontUrl
      value: http://{{cluster_ip}}:30080
  - name: minio
    needs: 
    - kalavai/longhorn
    namespace: minio
    chart: minio/minio
    installed: {{deploy_minio|default("false", true)}}
    set:
    - name: replicas
      value: {{minio_replicas}}
    - name: resources.requests.memory
      value: "{{minio_resources_memory}}"
    - name: persistence.enabled
      value: true
    - name: persistence.storageClass
      value: {{minio_persistence_storageClass}}
    - name: persistence.size
      value: "{{minio_persistence_size}}"
    - name: persistence.accessMode
      value: "ReadWriteMany"
    - name: rootUser
      value: {{minio_rootUser}}
    - name: rootPassword
      value: {{minio_rootPassword}}
    - name: service.type
      value: "NodePort"
    - name: service.nodePort
      value: {{minio_service_port}}
    - name: consoleService.type
      value: "NodePort"
    - name: consoleService.nodePort
      value: {{minio_console_port}}
    - name: buckets[0].name
      value: "llm-storage"
    - name: buckets[0].policy
      value: "public"
    - name: buckets[0].purge
      value: false
  - name: helios
    namespace: kalavai
    chart: kalavai/kalavai-helios
    version: "0.1.11"
    installed: {{deploy_helios|default("false", true)}}
    set:
    - name: deployment.watcher_endpoint
      value: "http://{{watcher_service}}"
    - name: deployment.watcher_auth_key
      value: "{{watcher_readonly_key}}"
    - name: deployment.kalavai_api_endpoint
      value: {{kalavai_api_endpoint}}
    - name: deployment.user_node_label
      value: "{{user_node_label}}"
    - name: deployment.sleep_interval
      value: "{{helios_harvest_interval}}"
  - name: opencost
    namespace: opencost
    chart: opencost-charts/opencost
    installed: {{deploy_opencost|default("false", true)}}
    set:
    - name: service.type
      value: NodePort
    - name: opencost.nodeSelector.{{kalavai_role_label}}
      value: server
    # point at prometheus instance (theres an opencost.prometheus.external too)
    - name: opencost.prometheus.internal.enabled
      value: true
    - name: opencost.prometheus.internal.serviceName
      value: {{prometheus_service_name}}
    - name: opencost.prometheus.internal.namespaceName
      value: {{prometheus_namespace}}
    - name: opencost.prometheus.internal.port
      value: {{prometheus_port}}
  - name: prometheus
    namespace: {{prometheus_namespace}}
    chart: prometheus-community/kube-prometheus-stack #prometheus/prometheus
    installed: {{deploy_prometheus|default("false", true)}}
    set:
    - name: server.nodeSelector.{{kalavai_role_label}}
      value: server
    - name: prometheus-pushgateway.enabled
      value: false
    - name: alertmanager.enabled
      value: false
    - name: server.retention
      value: {{prometheus_server_retention}}
    - name: server.persistentVolume.size
      value: {{prometheus_disk_size}}
    - name: prometheus-node-exporter.hostRootFsMount.enabled
      value: false
  - name: volcano-sh
    namespace: kalavai
    chart: volcano-sh/volcano
    installed: {{deploy_volcano|default("false", true)}}
    version: "1.13.0"
  - name: kuberay
    namespace: kuberay
    chart: kuberay/kuberay-operator
    installed: {{deploy_kuberay|default("false", true)}}
    version: "1.5.0"
  - name: kuberay-apiserver
    namespace: kuberay
    chart: kuberay/kuberay-apiserver
    installed: {{deploy_kuberay|default("false", true)}}
  - name: longhorn
    namespace: kalavai
    chart: longhorn/longhorn
    installed: {{deploy_longhorn|default("false", true)}}
    set:
    # security issue! enable for testing only
    - name: service.ui.type
      value: NodePort
    - name: service.ui.nodePort
      value: {{longhorn_ui_port}}
    - name: service.manager.type
      value: NodePort
    - name: service.manager.nodePort
      value: {{longhorn_manager_port}}
    - name: persistence.defaultClassReplicaCount
      value: {{longhorn_replicas}}
    - name: global.nodeSelector.{{longhorn_label_selector_key}}
      value: "{{longhorn_label_selector_value}}"
    - name: defaultSettings.storageMinimalAvailablePercentage
      value: {{longhorn_minimal_available_percentage}}
  - name: kalavai-watcher
    namespace: kalavai
    chart: kalavai/kalavai-watcher
    version: "0.4.0"
    installed: {{deploy_watcher|default("false", true)}}
    set:
    - name: namespace
      value: kalavai
    - name: deployment.replicas
      value: {{watcher_replicas}}
    - name: image_tag
      value: "{{watcher_image_tag}}" #"v2025.07.34"
    - name: deployment.in_cluster
      value: "True"
    - name: deployment.kalavai_username_key
      value: "{{kalavai_username_key}}"
    - name: deployment.use_auth_key
      value: "True"
    - name: deployment.admin_key
      value: "{{watcher_admin_key}}"
    - name: deployment.write_key
      value: "{{watcher_write_key}}"
    - name: deployment.readonly_key
      value: "{{watcher_readonly_key}}"
    - name: deployment.is_shared_pool
      value: {{watcher_is_shared_pool}}
    - name: deployment.allow_unregistered_user
      value: "{{watcher_allow_unregistered_user}}"
    - name: deployment.kalavai_api_endpoint
      value: {{kalavai_api_endpoint}}
    - name: deployment.prometheus_endpoint
      value: "http://{{prometheus_service_name}}.{{prometheus_namespace}}.svc.cluster.local:{{prometheus_port}}"
    - name: deployment.opencost_endpoint
      value: {{opencost_endpoint}}
    - name: deployment.longhorn_manager_endpoint
      value: {{longhorn_manager_endpoint}}
    - name: service.nodePort
      value: {{watcher_port}}
    - name: resources.limits.memory
      value: {{watcher_resources_memory}}
    - name: resources.limits.cpu
      value: {{watcher_resources_cpu}}
    - name: deployment.nodeSelector.{{kalavai_role_label}}
      value: "server"
  - name: hami-vgpu
    namespace: kalavai
    chart: hami-charts/hami
    installed: {{deploy_hami|default("false", true)}}
    version: "2.6.1"
    set:
    - name: resourceCores
      value: "nvidia.com/gpucores"
    - name: resourceMem
      value: "nvidia.com/gpumem"
    - name: resourceMemPercentage
      value: "nvidia.com/gpumem-percentage"
    - name: devicePlugin.runtimeClassName
      value: "nvidia"
    - name: scheduler.defaultSchedulerPolicy.nodeSchedulerPolicy
      value: "binpack"
    - name: scheduler.defaultSchedulerPolicy.gpuSchedulerPolicy
      value: "binpack"
    - name: scheduler.defaultCores
      value: "100"
    - name: scheduler.kubeScheduler.imageTag
      value: v1.31.1
    - name: devicePlugin.deviceMemoryScaling
      value: "1"
    - name: devicePlugin.deviceSplitCount
      value: "1"
    

