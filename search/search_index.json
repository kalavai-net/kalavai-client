{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Kalavai","text":"<p>Kalavai is an open source platform that turns everyday devices into your very own AI supercomputer. We help you aggregate resources from multiple machines: home desktops, gaming laptops, work computers, cloud VMs... When you need to go beyond, Kalavai facilitates matchmaking of resources so anyone in our community can tap into a larger pool of devices by inspiring others to join your cause.</p> <p>Want to be notified of the latest features? </p> <p>We regularly publish news, articles and updates on our Substack channel.</p> <p>Subscribe to our substack</p>"},{"location":"#what-does-kalavai-do","title":"What does Kalavai do","text":"<p>Kalavai's goal is to make AI hardware accessible and affordable to all. We do it in two ways:</p> <ol> <li> <p>The open source version can be used to pool any devices, for commercial and non-commercial purposes. This is perfect as a management layer for research groups and organisations that already have hardware lying around and wish to unlock its power, without requiring a devops team. These AI pools are free, secure and totally private.</p> </li> <li> <p>Our managed version acts as a social network for AI computing, facilitating users to connect with the community's resources. Think Reddit, but instead of memes, users share resources with inspiring projects.</p> </li> </ol>"},{"location":"#compatibility-matrix","title":"Compatibility matrix","text":"<p>If your system is not currently supported, open an issue and request it. We are expanding this list constantly.</p>"},{"location":"#os-compatibility","title":"OS compatibility","text":"<p>Currently compatible and tested OS: - Debian-based linux (such as Ubuntu) - Windows 10+ (using WSL2)</p> <p>Currently compatible (untested. Interested in testing them?): - Fedora - RedHat - Any distro capable of installing <code>.deb</code> and <code>.rpm</code> packages.</p> <p>Currently not compatible: - MacOS</p>"},{"location":"#hardware-compatibility","title":"Hardware compatibility:","text":"<ul> <li><code>amd64</code> or <code>x86_64</code> CPU architecture</li> <li>(optional) NVIDIA GPU</li> <li>AMD and Intel GPUs are currently not supported (yet!)</li> </ul>"},{"location":"#contribute","title":"Contribute","text":"<ul> <li>PR welcome!</li> <li>Join the community and share ideas!</li> <li>Report bugs, issues and new features.</li> <li>Help improve our compatibility matrix by testing on different operative systems.</li> <li>Community integrations are template jobs built by Kalavai and the community that makes deploying distributed workflows easy for users. Anyone can extend them and contribute to this repo.</li> <li>Join our mailing list for release updates and priority access to new features!</li> </ul>"},{"location":"#getting-started","title":"Getting started","text":"<p>Check out our quick start guide to get you going!</p>"},{"location":"concepts/","title":"Concepts","text":"<p>Work in progress</p>","tags":["concepts","architecture","pool"]},{"location":"concepts/#core-concepts","title":"Core concepts","text":"<p>Under construction. Come back soon!</p> <p>A platform to turn everyday devices into a powerful AI cloud</p>","tags":["concepts","architecture","pool"]},{"location":"concepts/#how-it-works","title":"How it works?","text":"<p>To create an AI pool, you need a seed node which acts as a control plane. It handles bookkeeping for the pool. With a seed node, you can generate join tokens, which you can share with other machines --worker nodes.</p> <p>The more worker nodes you have in a pool, the bigger workloads it can run. Note that the only requirement for a fully functioning pool is a single seed node.</p> <p>Once you have a pool running, you can easily deploy workloads using template jobs. These are community integrations that let users deploy jobs, such as LLM deployments or LLM fine tuning. A template makes using Kalavai really easy for end users, with a parameterised interface, and it also makes the platform infinitely expandable.</p>","tags":["concepts","architecture","pool"]},{"location":"faqs/","title":"FAQs","text":"<p>Work in progress</p>","tags":["FAQs"]},{"location":"faqs/#general","title":"General","text":"","tags":["FAQs"]},{"location":"faqs/#what-are-ai-pools","title":"What are AI pools?","text":"<p>In Kalavai parlor, a pool refers to a group of resources. We go beyond machine procurement and include everything a team needs to work on AI; from the hardware devices (GPUs, CPUs and memory) to the setup of a distributed environment and the tech stack needed to make it useful.</p> <p>Kalavai aims to manage it all (procurement of additional cloud resources, installing and configuring open source and industry standard frameworks, configuration management, facilitate distributed computing) so teams can focus on AI innovation.</p>","tags":["FAQs"]},{"location":"faqs/#isnt-the-performance-of-distributed-training-much-slower","title":"Isn\u2019t the performance of distributed training much slower?","text":"<p>Distributed computing is not an option: due to the skyrocketing demand in computation from AI models, we are going to need to use multiple devices to do training and inference. </p> <p>NVIDIA cannot get devices larger fast enough, and cloud providers are busy counting the money they are going to make from all that computing to care.</p> <p>Kalavai has considerable tailwinds that will work to minimise the impact of distributed computing in the future:  - Consumer-grade GPU performance per dollar is improving at a faster rate than cloud GPUs - By 2030: Internet broadband speed will reach Gbit/s and 6G will reduce latency &lt; 1 microsecond</p>","tags":["FAQs"]},{"location":"faqs/#host-nodes","title":"Host nodes","text":"","tags":["FAQs"]},{"location":"faqs/#what-are-the-minimum-specs-for-sharing","title":"What are the minimum specs for sharing?","text":"","tags":["FAQs"]},{"location":"faqs/#is-my-device-safe","title":"Is my device safe?","text":"","tags":["FAQs"]},{"location":"faqs/#can-i-use-my-device-whilst-sharing","title":"Can I use my device whilst sharing?","text":"","tags":["FAQs"]},{"location":"faqs/#can-i-limit-what-i-share-with-kalavai","title":"Can I limit what I share with Kalavai?","text":"","tags":["FAQs"]},{"location":"faqs/#can-i-run-the-kalavai-app-within-a-vm","title":"Can I run the kalavai app within a VM?","text":"","tags":["FAQs"]},{"location":"faqs/#why-does-it-require-sudo-privileges","title":"Why does it require sudo privileges?","text":"","tags":["FAQs"]},{"location":"faqs/#developers","title":"Developers","text":"","tags":["FAQs"]},{"location":"faqs/#there-are-plenty-of-mlops-platforms-out-there-why-would-organisations-turn-to-you-instead","title":"There are plenty of MLOps platforms out there, why would organisations turn to you instead?","text":"<p>MLOps solutions out there are great, and they continue to develop. But they all need hardware to run on; whether it is on premise servers, public cloud resources or managed services. </p> <p>We think of MLOps platforms as complementors, that\u2019s why we are building a marketplace for third parties to bring their solutions to our users. Since we manage the computing layer, we abstract away the complexity of integration for them, so they can also bring their tools without having to build multiple integrations.</p>","tags":["FAQs"]},{"location":"faqs/#enterprises","title":"Enterprises","text":"","tags":["FAQs"]},{"location":"faqs/#you-are-leveraging-the-organisations-existing-hardware-but-this-is-unlikely-to-meet-ai-demands-are-we-not-back-to-square-one-since-they-need-to-anyways-go-to-the-cloud","title":"You are leveraging the organisation's existing hardware, but this is unlikely to meet AI demands. Are we not back to square one since they need to anyways go to the cloud?","text":"<p>Our goal is not to narrow companies' choices but to manage the complexity of hybrid clouds. Organisations can bring hardware from anywhere (their own premises, their company devices, all the way to multi cloud on-demand resources) and Kalavai manages them equally. Developers then see a pool of resources that they treat the same.</p>","tags":["FAQs"]},{"location":"faqs/#organisations-with-on-premise-servers-already-have-systems-to-use-them-why-would-they-trust-you-to-manage-that-for-all-their-needs","title":"Organisations with on premise servers already have systems to use them. Why would they trust you to manage that for all their needs?","text":"<p>Kalavai works as an integration system, it does not force organisations to switch every workflow they have over to benefit from it. They can install the kalavai client in their existing on premise servers, which will automatically then connect them to the pool and make them able to run workflows. The kalavai client is designed to co-exist with any application and can be limited to use only a portion of resources, so organisations can easily continue to use their on premise deployments.</p>","tags":["FAQs"]},{"location":"faqs/#ive-heard-of-a-bunch-of-service-providers-for-rent-a-gpu-on-demand-isnt-the-market-saturated-already","title":"I\u2019ve heard of a bunch of service providers for rent-a-GPU on demand. Isn\u2019t the market saturated already?","text":"<p>Kalavai does not have any hardware to lease. We believe there are enough providers out there to cover that. Where there\u2019s a gap is in managing the complexity of use cases that require distributed computing. When workflows require more than one computing device to run, organisations need to manage the orchestration, maintenance and coordination of devices.</p> <p>We have designed Kalavai to integrate nicely with almost any computing resource out there, from public cloud, serverless GPU providers and on premise devices.</p> <p>Got another question?</p>","tags":["FAQs"]},{"location":"getting_started/","title":"Getting started","text":"<p>Kalavai is free to use, no caps, for both commercial and non-commercial purposes. All you need to get started is one or more computers that can see each other (i.e. within the same network), and you are good to go. If you wish to join computers in different locations / networks, check our managed kalavai offering.</p> <p>The <code>kalavai</code> CLI is the main tool to interact with the Kalavai platform, to create and manage both local and public pools. Let's go over its installation</p>","tags":["kalavai-client","cli","install","requirements","quick start"]},{"location":"getting_started/#requirements","title":"Requirements","text":"<ul> <li>A laptop, desktop or Virtual Machine</li> <li>Admin / privileged access (eg. <code>sudo</code> access in linux or Administrator in Windows)</li> <li>Running Windows or Linux (see more details in our compatibility matrix)</li> </ul>","tags":["kalavai-client","cli","install","requirements","quick start"]},{"location":"getting_started/#linux","title":"Linux","text":"<p>Run the following command on your terminal:</p> <pre><code>curl -sfL https://raw.githubusercontent.com/kalavai-net/kalavai-client/main/assets/install_client.sh | bash -\n</code></pre>","tags":["kalavai-client","cli","install","requirements","quick start"]},{"location":"getting_started/#windows","title":"Windows","text":"<p>For Windows machines complete WSL configuration first before continuing. You must be running Windows 10 version 2004 and higher (Build 19041 and higher) or Windows 11 to use the commands below. If you are on earlier versions please see the manual install page.</p> <ol> <li> <p>Open a PowerShell with administrative permissions (Run as Administrator)</p> </li> <li> <p>Install WSL2:</p> </li> </ol> <pre><code>wsl --install -d Ubuntu-24.04\n</code></pre> <ol> <li>Make sure to enable <code>systemd</code> by editing (or creating if required) a file <code>/etc/wsl.conf</code></li> </ol> <pre><code>[boot]\nsystemd=true\n</code></pre> <ol> <li>Restart the WSL instance by exiting and logging back in:</li> </ol> <pre><code>exit\nwsl --shutdown\nwsl -d Ubuntu-24.04\n</code></pre> <ol> <li>Inside WSL, install Kalavai:</li> </ol> <pre><code>curl -sfL https://raw.githubusercontent.com/kalavai-net/kalavai-client/main/assets/install_client.sh | bash -\n</code></pre> <p>Note: you must keep the WSL console window open to continue to share resources with an AI pool. If you restart your machine or close the console, you will need to resume kalavai as follows:</p> <pre><code>kalavai pool resume\n</code></pre> <p>Known issue: if the above resume command hangs or fails, try to run the pause command before and then reattempt resuming:</p> <pre><code>kalavai pool pause\nkalavai pool resume\n</code></pre>","tags":["kalavai-client","cli","install","requirements","quick start"]},{"location":"local_pool/","title":"Local pools","text":"","tags":["create local pool","bootstrap","seed node"]},{"location":"local_pool/#createa-a-local-pool","title":"Createa a local pool","text":"<p>Kalavai is free to use, no caps, for both commercial and non-commercial purposes. All you need to get started is one or more computers that can see each other (i.e. within the same network), and you are good to go. If you wish to join computers in different locations / networks, check managed kalavai.</p>","tags":["create local pool","bootstrap","seed node"]},{"location":"local_pool/#1-start-a-seed-node","title":"1. Start a seed node","text":"<p>Simply use the CLI to start your seed node:</p> <pre><code>kalavai pool start &lt;pool-name&gt;\n</code></pre> <p>Now you are ready to add worker nodes to this seed. To do so, generate a joining token:</p> <pre><code>$ kalavai pool token\n\nJoin token: &lt;token&gt;\n</code></pre>","tags":["create local pool","bootstrap","seed node"]},{"location":"local_pool/#2-add-worker-nodes","title":"2. Add worker nodes","text":"<p>Increase the power of your AI pool by inviting others to join.</p> <p>Copy the joining token. On the worker node, run:</p> <pre><code>kalavai pool join &lt;token&gt;\n</code></pre>","tags":["create local pool","bootstrap","seed node"]},{"location":"public_pool/","title":"Public pools: crowdsource community resources","text":"<p>Our public platform expands local pools in two key aspects: - Worker nodes no longer have to be in the same local network - Users can tap into community resources: inspire others in the community to join their projects with their resources</p> <p>To get started, you need is a free account on our platform.</p>","tags":["crowdsource","public pool"]},{"location":"public_pool/#a-tap-into-community-resources","title":"A) Tap into community resources","text":"<p>Create a new pool, using a public location provided by Kalavai:</p> <pre><code># Authenticate with your kalavai account\nkalavai login\n\n# Get available public locations\nkalavai location list\n\n\u250f\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513  \n\u2503 VPN \u2503 location    \u2503 subnet        \u2503          \n\u2521\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0   \u2502 uk_london_1 \u2502 100.10.0.0/16 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n# Create and publish your pool\nkalavai pool start &lt;pool-name&gt; --location uk_london_1\n</code></pre> <p>If all goes well, your pool will be created and published on the <code>Public Seeds</code> section of our platform</p> <p></p> <p>Note: to be able to publish pools your account needs to have sufficient karma points. Earn karma by sharing your resources with others.</p>","tags":["crowdsource","public pool"]},{"location":"public_pool/#b-share-resources-with-inspiring-community-projects","title":"B) Share resources with inspiring community projects","text":"<p>Have idle computing resources? Wish to be part of exciting public projects? Want to give back to the community? Earn social credit (both literally and metaphorically) by sharing your computer with others within the community.</p> <p>All you need is a public joining key. Get them in our platform, on the list of published pools. Press <code>Join</code> and follow the instructions</p> <p></p>","tags":["crowdsource","public pool"]},{"location":"ray/","title":"Ray","text":"<p>Work in progress</p>","tags":["ray"]},{"location":"ray/#ray-clusters-for-distributed-computing","title":"Ray clusters for distributed computing","text":"<p>From Ray's documentation:</p> <p>Ray is an open-source unified framework for scaling AI and Python applications like machine learning.</p> <p>Kalavai and Ray work perfectly together. Ray is a great framework to deal with distributed computation on top of an existing hardware pool. Kalavai acts as a unifying layer that brings that required hardware together for Ray to do its magic.</p> <p>To get started, check out our example to get a Ray cluster going. </p>","tags":["ray"]},{"location":"ray/#create-a-cluster","title":"Create a cluster","text":"<ul> <li>Specs how to define specs: kalavai pool resources (cpu, memory and nvidia.com/gpu)</li> </ul> <pre><code>$ kalavai pool resources\n\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \n\u2503           \u2503 n_nodes \u2503 cpu                \u2503 memory      \u2503 nvidia.com/gpu \u2503 \n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \n\u2502 Available \u2502 2       \u2502 10.684999999999999 \u2502 16537780224 \u2502 1              \u2502 \n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \n\u2502 Total     \u2502 4       \u2502 42                 \u2502 70895030272 \u2502 3              \u2502 \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \n</code></pre> <pre><code>spec:\n  ...\n  headGroupSpec:\n    ...\n    template:\n      spec:\n        ...\n        containers:\n        ...\n          resources:\n            limits:\n              cpu: 2\n              memory: 4Gi\n            requests:\n              cpu: 2\n              memory: 4Gi\n  workerGroupSpecs:\n  ...\n    template:\n      spec:\n        containers:\n        ...\n          resources:\n            limits:\n              nvidia.com/gpu: 1\n              cpu: 2\n              memory: 4Gi\n            requests:\n              nvidia.com/gpu: 1\n              cpu: 2\n              memory: 4Gi\n</code></pre> <p>Interact with Ray - Interactive mode - Endpoint - RayJobs</p>","tags":["ray"]},{"location":"ray/#advanced-topics","title":"Advanced topics","text":"<p>Autoscaling</p> <p>Node hardware requirements (limits vs requests)</p>","tags":["ray"]},{"location":"templates/","title":"Develop with Kalavai","text":"<p>Work in progress</p>","tags":["integrations","install apps","ray","dask","vcluster"]},{"location":"templates/#install-applications","title":"Install applications","text":"","tags":["integrations","install apps","ray","dask","vcluster"]},{"location":"templates/#ray","title":"Ray","text":"","tags":["integrations","install apps","ray","dask","vcluster"]},{"location":"templates/#dask","title":"Dask","text":"","tags":["integrations","install apps","ray","dask","vcluster"]},{"location":"templates/#vcluster","title":"vCluster","text":"","tags":["integrations","install apps","ray","dask","vcluster"]},{"location":"templates/#why-is-insert-preferred-application-not-supported","title":"Why is [insert preferred application] not supported?","text":"<p>If your preferred distributed ML application is not yet supported, let us know!</p> <p>Contact us</p>","tags":["integrations","install apps","ray","dask","vcluster"]}]}