- name: litellm_key
  value: "sk-1234"
  default: "sk-1234"
  description: "Master key of the LiteLLM service (central registry)"

- name: workers
  value: 2
  default: 1
  description: "Number of remote workers (for tensor and pipeline parallelism). This is in addition to the main node"

- name: model_id
  value: Qwen/Qwen2.5-1.5B-Instruct
  default: null
  description: "Huggingface model id to load"

- name: working_memory
  value: 5
  default: 5
  description: "Pool storage to use to cache model weights"

- name: memory
  value: 10
  default: 8
  description: "RAM memory per single worker (final one = memory * num_workers)"

- name: pipeline_parallel_size
  value: 2
  default: 1
  description: "Pipeline parallelism (use the number of nodes)"

- name: extra
  value: "--dtype float16"
  default: ""
  description: "Extra parameters to pass to the vLLM server. See https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html#command-line-arguments-for-the-server"
